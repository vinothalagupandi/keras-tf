{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238a3eb1-ef98-4e1e-8f1c-cd36035de2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries.\n",
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f8bace-9300-42b3-a8c7-8333487489e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variables for urls of datasets.\n",
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f01f3b-b0b1-44dc-a367-ec8bf3f1ea18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "30874/30874 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
      "13049/13049 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Creating variables for paths of datasets.\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\",  TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b161a7a-5cf0-4e94-be9b-55d9047a2fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting train_file_path into pandas dataframe.\n",
    "train_df = pd.read_csv(train_file_path, header='infer')\n",
    "test_df = pd.read_csv(test_file_path, header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b59237-6413-412a-bf74-ad843c9eae1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a look titanic dataset.\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73a8b56-4447-4bca-aa12-66cba1d62421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Second</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
       "0           0    male  22.0                   1      0   7.2500   Third   \n",
       "1           1  female  38.0                   1      0  71.2833   First   \n",
       "2           1  female  26.0                   0      0   7.9250   Third   \n",
       "3           1  female  35.0                   1      0  53.1000   First   \n",
       "4           0    male  28.0                   0      0   8.4583   Third   \n",
       "..        ...     ...   ...                 ...    ...      ...     ...   \n",
       "622         0    male  28.0                   0      0  10.5000  Second   \n",
       "623         0    male  25.0                   0      0   7.0500   Third   \n",
       "624         1  female  19.0                   0      0  30.0000   First   \n",
       "625         0  female  28.0                   1      2  23.4500   Third   \n",
       "626         0    male  32.0                   0      0   7.7500   Third   \n",
       "\n",
       "        deck  embark_town alone  \n",
       "0    unknown  Southampton     n  \n",
       "1          C    Cherbourg     n  \n",
       "2    unknown  Southampton     y  \n",
       "3          C  Southampton     n  \n",
       "4    unknown   Queenstown     y  \n",
       "..       ...          ...   ...  \n",
       "622  unknown  Southampton     y  \n",
       "623  unknown  Southampton     y  \n",
       "624        B  Southampton     y  \n",
       "625  unknown  Southampton     n  \n",
       "626  unknown   Queenstown     y  \n",
       "\n",
       "[627 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73a1de1-1764-47e9-940e-ff62f7ea9e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vinothalagupandi/.local/lib/python3.8/site-packages/tensorflow/python/data/experimental/ops/readers.py:573: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ignore_errors` instead.\n"
     ]
    }
   ],
   "source": [
    "#Creating the target and featrues variables.\n",
    "LABEL_COLUMN = 'survived'\n",
    "LABELS = [0, 1]\n",
    "# Let's specify file path, batch size, label name, missing value parameters in make_csv_dataset method.\n",
    "train_ds = tf.data.experimental.make_csv_dataset(\n",
    "        train_file_path,\n",
    "        batch_size = 3,\n",
    "        label_name=LABEL_COLUMN,\n",
    "        na_value=\"?\",\n",
    "        num_epochs= 1,\n",
    "        ignore_errors=True)\n",
    "# Let's create test dataset as above.\n",
    "test_ds = tf.data.experimental.make_csv_dataset(\n",
    "        test_file_path,\n",
    "        batch_size=3,\n",
    "        label_name=LABEL_COLUMN,\n",
    "        na_value=\"?\",\n",
    "        num_epochs=1,\n",
    "        ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05d71d1-5292-4839-81cc-5ab8a2453497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 0 0], shape=(3,), dtype=int32)\n",
      "sex: [b'female' b'male' b'male']\n",
      "age: [22. 28. 28.]\n",
      "n_siblings_spouses: [0 0 0]\n",
      "parch: [0 0 0]\n",
      "fare: [151.55     7.8958  52.    ]\n",
      "class: [b'First' b'Third' b'First']\n",
      "deck: [b'unknown' b'unknown' b'A']\n",
      "embark_town: [b'Southampton' b'Cherbourg' b'Southampton']\n",
      "alone: [b'y' b'y' b'y']\n"
     ]
    }
   ],
   "source": [
    "for batch, label in train_ds.take(1):\n",
    "    print(label)\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key}: {value.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f9419c2-60e0-4c30-8ce0-9d610007c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_10884/2062204455.py:5: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "# Setting numeric columns\n",
    "feature_columns = []\n",
    "# numeric columns\n",
    "for header in ['age', 'n_siblings_spouses', 'parch', 'fare']:\n",
    "    feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20fce8c6-df23-44b7-9830-7259896c97d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.387560</td>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.487582</td>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived         age  n_siblings_spouses       parch        fare\n",
       "count  627.000000  627.000000          627.000000  627.000000  627.000000\n",
       "mean     0.387560   29.631308            0.545455    0.379585   34.385399\n",
       "std      0.487582   12.511818            1.151090    0.792999   54.597730\n",
       "min      0.000000    0.750000            0.000000    0.000000    0.000000\n",
       "25%      0.000000   23.000000            0.000000    0.000000    7.895800\n",
       "50%      0.000000   28.000000            0.000000    0.000000   15.045800\n",
       "75%      1.000000   35.000000            1.000000    0.000000   31.387500\n",
       "max      1.000000   80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(train_file_path, header='infer')\n",
    "titanic_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f6e19b9-11f8-4f53-bc23-2e643a4d095b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_10884/2714876157.py:3: bucketized_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "# Bucketizing age columns\n",
    "age = feature_column.numeric_column('age')\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[23, 28, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e5e125-bc4b-4503-ba32-0ecce67995e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex : ['male' 'female']\n",
      "class : ['Third' 'First' 'Second']\n",
      "deck : ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town : ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone : ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "#Deteriming categorical columns\n",
    "h = {}\n",
    "for col in titanic_df:\n",
    "    if col in ['sex', 'class', 'deck', 'embark_town', 'alone']:\n",
    "        print(col, ':', titanic_df[col].unique())\n",
    "        h[col] = titanic_df[col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfbd5e5f-5eeb-4c20-a6f1-a9a1d2309c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_10884/4266679419.py:2: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_10884/4266679419.py:4: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "# Converting categorical columns and encoding unique categorical values\n",
    "sex_type = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'Type', h.get('sex').tolist())\n",
    "sex_type_one_hot = feature_column.indicator_column(sex_type)\n",
    "\n",
    "class_type = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'Type', h.get('class').tolist())\n",
    "class_type_one_hot = feature_column.indicator_column(class_type)\n",
    "\n",
    "deck_type = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'Type', h.get('deck').tolist())\n",
    "deck_type_one_hot = feature_column.indicator_column(deck_type)\n",
    "\n",
    "embark_town_type = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'Type', h.get('embark_town').tolist())\n",
    "embark_town_type_one_hot = feature_column.indicator_column(embark_town_type)\n",
    "\n",
    "alone_type = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'Type', h.get('alone').tolist())\n",
    "alone_one_hot = feature_column.indicator_column(alone_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cca4a30c-ac2a-4d3c-a240-869d7d59d262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_10884/3640364463.py:4: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "# Embeding the \"deck\" column and reducing its dimension to 3.\n",
    "deck = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'deck', titanic_df.deck.unique())\n",
    "deck_embedding = feature_column.embedding_column(deck, dimension=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba075a5c-2771-4f80-839c-607e668cadb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_10884/1527213909.py:2: categorical_column_with_hash_bucket (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "# Reducing class column\n",
    "class_hashed = feature_column.categorical_column_with_hash_bucket(\n",
    "      'class', hash_bucket_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7064f55-3b66-4d7d-8a53-78bd014dc0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_10884/895436336.py:1: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n"
     ]
    }
   ],
   "source": [
    "cross_type_feature = feature_column.crossed_column(['sex', 'class'], hash_bucket_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438e1443-1db4-427f-88fe-00db3a499abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# appending numeric columns\n",
    "for header in ['age', 'n_siblings_spouses', 'parch', 'fare']:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "    \n",
    "# appending bucketized columns\n",
    "age = feature_column.numeric_column('age')\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[23, 28, 35])\n",
    "feature_columns.append(age_buckets)\n",
    "\n",
    "# appending categorical columns\n",
    "indicator_column_names = ['sex', 'class', 'deck', 'embark_town', 'alone']\n",
    "for col_name in indicator_column_names:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        col_name, titanic_df[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "    \n",
    "# appending embedding columns\n",
    "deck = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'deck', titanic_df.deck.unique())\n",
    "deck_embedding = feature_column.embedding_column(deck, dimension=3)\n",
    "feature_columns.append(deck_embedding)\n",
    "\n",
    "# appending crossed columns\n",
    "feature_columns.append(feature_column.indicator_column(cross_type_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aac7a321-a167-4caa-b8c6-ad52514a00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb09ac93-3ece-462c-8331-d775c64c6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, test_df = train_test_split(test_df, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e5a467-cb61-499d-97ab-2d63d502e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df.pop(\"survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "168bfb52-3dae-4334-83c2-daded77afca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('survived')\n",
    "    # To transform the DataFrame into a key-value pair. \n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    # To shuffle and batch\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77e4a4aa-80ce-4428-a90d-0a7a3eaaf272",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "val_ds = pandas_to_dataset(val_df, shuffle=False, batch_size=batch_size)\n",
    "test_ds = pandas_to_dataset(test_df, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7143fc60-6221-4f38-b19b-b34b48b9fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d361c902-3375-47ec-9270-285b76838564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef7b34b9-9c0a-4d11-8913-c1a0a3b98602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.9115 - accuracy: 0.6491 - val_loss: 0.6283 - val_accuracy: 0.6203\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.7938 - accuracy: 0.6794 - val_loss: 0.6480 - val_accuracy: 0.6013\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.5722 - accuracy: 0.7305 - val_loss: 0.4655 - val_accuracy: 0.7215\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.5629 - accuracy: 0.7592 - val_loss: 0.4540 - val_accuracy: 0.7911\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.7767 - val_loss: 0.5799 - val_accuracy: 0.7025\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.5298 - accuracy: 0.7751 - val_loss: 0.4960 - val_accuracy: 0.7278\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.4969 - accuracy: 0.7847 - val_loss: 0.4343 - val_accuracy: 0.7911\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.4812 - accuracy: 0.7911 - val_loss: 0.4175 - val_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.4667 - accuracy: 0.7927 - val_loss: 0.4057 - val_accuracy: 0.8101\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.6899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fefa1ab3e20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
